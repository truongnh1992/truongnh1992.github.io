I",K<p>kubeadm is a tool which is a part of the Kubernetes project. It helps you deploy a Kubernetes cluster but it still has some limitations and one of these is that it doesn’t support multi-master nodes (HA). This article will show you the way to create a HA Cluster with kubeadm.</p>

<p><strong>Contents:</strong></p>

<!-- MarkdownTOC -->
<p><a href="#-preparation">1. Preparation</a></p>
<ul>
  <li><a href="#installing-bare-metal-server-and-creating-necessary-VMs">1.1. Installing bare-metal server and creating necessary VMs</a></li>
  <li><a href="#installing-docker">1.2. Installing docker kubelet kubeadm kubectl kubernetes-cni on master nodes and worker nodes</a></li>
  <li><a href="#installing-haproxy">1.3. Installing HAproxy load balancer</a></li>
</ul>

<p><a href="#-creating-HA-cluster-with-kubeadm">2. Creating HA cluster with kubeadm</a></p>
<ul>
  <li><a href="#steps-for-the-1st-master-node">2.1. Steps for the 1st master node</a></li>
  <li><a href="#steps-for-the-rest-of-the-master-nodes">2.2. Steps for the rest of the master nodes</a></li>
  <li><a href="#installing-workers">2.3. Installing workers</a></li>
</ul>

<p><a href="#-reference">3. Reference</a><br />
<!-- /MarkdownTOC --></p>

<p><a name="-preparation"><a></a></a></p>
<h2 id="1-preparation">1. Preparation</h2>

<p><a name="installing-bare-metal-server-and-creating-necessary-VMs"><a></a></a></p>
<h3 id="11-installing-bare-metal-server-and-creating-necessary-vms">1.1. Installing bare-metal server and creating necessary VMs</h3>

<p>The bare-metal server runs Ubuntu Server 16.04 and there are 7 Virtual Machines (VMs) will be installed on it. Both of the VMs also run Ubuntu Server 16.04.</p>

<ul>
  <li>3 master nodes</li>
  <li>3 worker nodes</li>
  <li>1 HAproxy load balancer</li>
</ul>

<p><img src="/static/img/multi-master-ha/Nodes.PNG" alt="nodes_configuration" /></p>

<p class="image-caption"><em>The configurations of nodes</em></p>

<p><img src="/static/img/multi-master-ha/stacketcd.png" alt="nodes_configuration" /></p>

<p class="image-caption"><em>The stacked etcd cluster</em></p>

<p><a name="installing-docker"><a></a></a></p>
<h3 id="12-installing-docker-kubelet-kubeadm-kubectl-kubernetes-cni-on-master-nodes-and-worker-nodes">1.2. Installing docker kubelet kubeadm kubectl kubernetes-cni on <code class="highlighter-rouge">master nodes</code> and <code class="highlighter-rouge">worker nodes</code></h3>

<p>Adding kubernetes repo:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>curl <span class="nt">-s</span> https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -
<span class="nv">$ </span><span class="nb">echo</span> <span class="s2">"deb http://apt.kubernetes.io/ kubernetes-xenial main"</span> <span class="o">&gt;&gt;</span> ~/kubernetes.list
<span class="nv">$ </span><span class="nb">sudo mv</span> ~/kubernetes.list /etc/apt/sources.list.d
<span class="nv">$ </span><span class="nb">sudo </span>apt-get update
</code></pre></div></div>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>apt-get <span class="nb">install</span> <span class="nt">-y</span> docker.io kubelet kubeadm kubectl kubernetes-cni <span class="nt">--allow-unauthenticated</span>
</code></pre></div></div>

<p><strong>If your machines (all of the above VMs) run behind the **proxy</strong>, please follow the instructions below. If NO, skip it and go to <a href="#13-installing-haproxy-load-balancer">section 1.3</a>**</p>

<p><strong>Configuring proxy for apt</strong></p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>vim /etc/apt/apt.conf

Acquire::http::proxy <span class="s2">"http://[Proxy_Server]:[Proxy_Port]/"</span><span class="p">;</span>
Acquire::HTTP::proxy <span class="s2">"http://[Proxy_Server]:[Proxy_Port]/"</span><span class="p">;</span>
</code></pre></div></div>

<p><strong>Configuring proxy for docker</strong></p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo mkdir</span> <span class="nt">-p</span> /etc/systemd/system/docker.service.d
<span class="nv">$ </span><span class="nb">sudo </span>vim /etc/systemd/system/docker.service.d/http-proxy.conf

<span class="o">[</span>Service]
<span class="nv">Environment</span><span class="o">=</span><span class="s2">"HTTP_PROXY=http://[Proxy_Server]:[Proxy_Port]/"</span>
</code></pre></div></div>
<p><a name="installing-haproxy"><a></a></a></p>
<h3 id="13-installing-haproxy-load-balancer">1.3. Installing HAproxy load balancer</h3>

<p>Installing haproxy on <code class="highlighter-rouge">ha machine</code> (IP: 10.0.2.33)</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>apt-get <span class="nb">install </span>haproxy
</code></pre></div></div>

<p>Configuring HAProxy to load balance the traffic between 3 master nodes.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>vim /etc/haproxy/haproxy.cfg
</code></pre></div></div>
<p>Modifying content of file <code class="highlighter-rouge">haproxy.cfg</code> as below:</p>
<pre><code class="language-cfg">global
        log /dev/log    local0
        log /dev/log    local1 notice
        chroot /var/lib/haproxy
...
...

frontend kubernetes
        bind 10.0.2.33:6443
        option tcplog
        mode tcp
        default_backend kubernetes-master-nodes

backend kubernetes-master-nodes
        mode tcp
        balance roundrobin
        option tcp-check
        server k8s-master1 10.0.2.11:6443 check fall 3 rise 2
        server k8s-master2 10.0.2.12:6443 check fall 3 rise 2
        server k8s-master3 10.0.2.13:6443 check fall 3 rise 2
</code></pre>

<ul>
  <li>
    <p>The health check for an apiserver is a TCP check on the port which the kube-apiserver listen on. The default value: <strong>6443</strong></p>
  </li>
  <li>
    <p>In frontend section: bind to <code class="highlighter-rouge">ha machine</code> IP address (10.0.2.33)</p>
  </li>
  <li>
    <p>In backend section: Notice the hostname and IP address of 3 master nodes</p>
  </li>
</ul>

<p>Restart the HAproxy</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>systemctl restart haproxy.service
</code></pre></div></div>
<p><a name="-creating-HA-cluster-with-kubeadm"><a></a></a></p>
<h2 id="2-creating-ha-cluster-with-kubeadm">2. Creating HA cluster with kubeadm</h2>

<p><a name="steps-for-the-1st-master-node"><a></a></a></p>
<h3 id="21-steps-for-the-1st-master-node">2.1. Steps for the 1st master node</h3>

<p>On the master node <code class="highlighter-rouge">master1</code> (IP: 10.0.2.11), create a configuration file <code class="highlighter-rouge">kubeadm-config.yaml</code>:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">apiVersion</span><span class="pi">:</span> <span class="s">kubeadm.k8s.io/v1beta1</span>
<span class="na">kind</span><span class="pi">:</span> <span class="s">ClusterConfiguration</span>
<span class="na">kubernetesVersion</span><span class="pi">:</span> <span class="s">stable</span>
<span class="na">apiServer</span><span class="pi">:</span>
  <span class="na">certSANs</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">10.0.2.33"</span>
<span class="na">controlPlaneEndpoint</span><span class="pi">:</span> <span class="s2">"</span><span class="s">10.0.2.33:6443"</span>
</code></pre></div></div>

<ul>
  <li>
    <p>The <code class="highlighter-rouge">kubernetesVersion</code> is the Kubernetes version which is using. This configuration uses <code class="highlighter-rouge">stable</code></p>
  </li>
  <li>
    <p>The <code class="highlighter-rouge">controlPlaneEndpoint</code> is the <code class="highlighter-rouge">ha machine</code>’s IP address with port 6443</p>
  </li>
</ul>

<p><strong>Deploying node master1:</strong></p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>kubeadm init <span class="nt">--config</span><span class="o">=</span>kubeadm-config.yaml
</code></pre></div></div>

<p>The terminal will print something like this:</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>...
You can now join any number of machines by running the following on each node
as root:

kubeadm join 10.0.2.33:6443 --token 7ju4yg.5x2xaj96xqx18qwq --discovery-token-ca-cert-hash sha256:4d7c5ef142e4faca3573984119df92a1a188115723f1e81dbb27eeb039cac1e0
</code></pre></div></div>

<p>Save the output <strong>kubeadm join 10.0.2.33:6443 –token…</strong> to a text file in order to join other <code class="highlighter-rouge">master nodes</code> to the cluster.</p>

<p>Applying the <a href="https://www.weave.works/blog/cni-for-docker-containers/">Weave</a> CNI plugin:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>kubectl apply <span class="nt">-f</span> <span class="s2">"https://cloud.weave.works/k8s/net?k8s-version=</span><span class="si">$(</span>kubectl version | <span class="nb">base64</span> | <span class="nb">tr</span> <span class="nt">-d</span> <span class="s1">'\n'</span><span class="si">)</span><span class="s2">"</span>
</code></pre></div></div>

<p><strong>Verifying that the pods of the components are ready</strong>:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-w</span>
</code></pre></div></div>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                                  READY   STATUS    RESTARTS   AGE
coredns-86c58d9df4-8vcxh              1/1     Running   0          4h38m
coredns-86c58d9df4-ts6x2              1/1     Running   0          4h38m
etcd-k8s-master1                      1/1     Running   0          4h37m
kube-apiserver-k8s-master1            1/1     Running   0          4h37m
kube-controller-manager-k8s-master1   1/1     Running   0          4h37m
kube-proxy-dhnjk                      1/1     Running   0          4h38m
kube-scheduler-k8s-master1            1/1     Running   0          4h37m
weave-net-cqb88                       2/2     Running   0          4h22m
</code></pre></div></div>

<blockquote>
  <p>Make sure that after the 1st master node has finished initializing, then join new master nodes.</p>
</blockquote>

<p><strong>Copy the certificate files from the <code class="highlighter-rouge">1st master node</code> to the <code class="highlighter-rouge">master2</code> and <code class="highlighter-rouge">master3</code></strong></p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vim copy.sh

<span class="nv">USER</span><span class="o">=</span>root
<span class="nv">MASTER_NODE_IPS</span><span class="o">=</span><span class="s2">"10.0.2.12 10.0.2.13"</span>
<span class="k">for </span>host <span class="k">in</span> <span class="k">${</span><span class="nv">MASTER_NODE_IPS</span><span class="k">}</span><span class="p">;</span> <span class="k">do
   </span>scp /etc/kubernetes/pki/ca.crt <span class="s2">"</span><span class="k">${</span><span class="nv">USER</span><span class="k">}</span><span class="s2">"</span>@<span class="nv">$host</span>:
   scp /etc/kubernetes/pki/ca.key <span class="s2">"</span><span class="k">${</span><span class="nv">USER</span><span class="k">}</span><span class="s2">"</span>@<span class="nv">$host</span>:
   scp /etc/kubernetes/pki/sa.key <span class="s2">"</span><span class="k">${</span><span class="nv">USER</span><span class="k">}</span><span class="s2">"</span>@<span class="nv">$host</span>:
   scp /etc/kubernetes/pki/sa.pub <span class="s2">"</span><span class="k">${</span><span class="nv">USER</span><span class="k">}</span><span class="s2">"</span>@<span class="nv">$host</span>:
   scp /etc/kubernetes/pki/front-proxy-ca.crt <span class="s2">"</span><span class="k">${</span><span class="nv">USER</span><span class="k">}</span><span class="s2">"</span>@<span class="nv">$host</span>:
   scp /etc/kubernetes/pki/front-proxy-ca.key <span class="s2">"</span><span class="k">${</span><span class="nv">USER</span><span class="k">}</span><span class="s2">"</span>@<span class="nv">$host</span>:
   scp /etc/kubernetes/pki/etcd/ca.crt <span class="s2">"</span><span class="k">${</span><span class="nv">USER</span><span class="k">}</span><span class="s2">"</span>@<span class="nv">$host</span>:etcd-ca.crt
   scp /etc/kubernetes/pki/etcd/ca.key <span class="s2">"</span><span class="k">${</span><span class="nv">USER</span><span class="k">}</span><span class="s2">"</span>@<span class="nv">$host</span>:etcd-ca.key
   scp /etc/kubernetes/admin.conf <span class="s2">"</span><span class="k">${</span><span class="nv">USER</span><span class="k">}</span><span class="s2">"</span>@<span class="nv">$host</span>:
<span class="k">done</span>
</code></pre></div></div>

<p>Run above script with user <code class="highlighter-rouge">root</code> of <strong>1st master node</strong>.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>root@k8s-master1:~# sh copy.sh
</code></pre></div></div>
<p>After running successfully <code class="highlighter-rouge">copy.sh</code>, the certificates will be located in directory <code class="highlighter-rouge">/root</code> of nodes: <strong>master2</strong> and <strong>master3</strong>.</p>

<p><a name="steps-for-the-rest-of-the-master-nodes"><a></a></a></p>
<h3 id="22-steps-for-the-rest-of-the-master-nodes">2.2. Steps for the rest of the master nodes</h3>

<p>Move the files created by the previous step where <code class="highlighter-rouge">scp</code> was used:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>vim move.sh

<span class="nv">USER</span><span class="o">=</span>root
<span class="nb">mkdir</span> <span class="nt">-p</span> /etc/kubernetes/pki/etcd
<span class="nb">mv</span> /<span class="k">${</span><span class="nv">USER</span><span class="k">}</span>/ca.crt /etc/kubernetes/pki/
<span class="nb">mv</span> /<span class="k">${</span><span class="nv">USER</span><span class="k">}</span>/ca.key /etc/kubernetes/pki/
<span class="nb">mv</span> /<span class="k">${</span><span class="nv">USER</span><span class="k">}</span>/sa.pub /etc/kubernetes/pki/
<span class="nb">mv</span> /<span class="k">${</span><span class="nv">USER</span><span class="k">}</span>/sa.key /etc/kubernetes/pki/
<span class="nb">mv</span> /<span class="k">${</span><span class="nv">USER</span><span class="k">}</span>/front-proxy-ca.crt /etc/kubernetes/pki/
<span class="nb">mv</span> /<span class="k">${</span><span class="nv">USER</span><span class="k">}</span>/front-proxy-ca.key /etc/kubernetes/pki/
<span class="nb">mv</span> /<span class="k">${</span><span class="nv">USER</span><span class="k">}</span>/etcd-ca.crt /etc/kubernetes/pki/etcd/ca.crt
<span class="nb">mv</span> /<span class="k">${</span><span class="nv">USER</span><span class="k">}</span>/etcd-ca.key /etc/kubernetes/pki/etcd/ca.key
<span class="nb">mv</span> /<span class="k">${</span><span class="nv">USER</span><span class="k">}</span>/admin.conf /etc/kubernetes/admin.conf
</code></pre></div></div>

<p><strong>On node master2:</strong></p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>root@k8s-master2:~# sh move.sh
</code></pre></div></div>

<p><strong>On node master3:</strong></p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>root@k8s-master3:~# sh move.sh
</code></pre></div></div>

<p>Start <strong><code class="highlighter-rouge">kubeadm join</code></strong> on nodes master2 and master3 using the join command in section 2.1 and add the flag <code class="highlighter-rouge">--experimental-control-plane</code></p>

<p><strong>On node master2:</strong></p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>kubeadm <span class="nb">join </span>10.0.2.33:6443 <span class="nt">--token</span> 7ju4yg.5x2xaj96xqx18qwq <span class="nt">--discovery-token-ca-cert-hash</span> sha256:4d7c5ef142e4faca3573984119df92a1a188115723f1e81dbb27eeb039cac1e0 <span class="nt">--experimental-control-plane</span>
</code></pre></div></div>

<p><img src="/static/img/multi-master-ha/join-master2.PNG" alt="master2-join" /></p>

<p><strong>On node master3:</strong></p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>kubeadm <span class="nb">join </span>10.0.2.33:6443 <span class="nt">--token</span> 7ju4yg.5x2xaj96xqx18qwq <span class="nt">--discovery-token-ca-cert-hash</span> sha256:4d7c5ef142e4faca3573984119df92a1a188115723f1e81dbb27eeb039cac1e0 <span class="nt">--experimental-control-plane</span>
</code></pre></div></div>

<p><img src="/static/img/multi-master-ha/join-master3.PNG" alt="master3-join" /></p>

<p><strong>Verifying that the pods of the components are ready</strong>:</p>
<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>kubectl get pod <span class="nt">-n</span> kube-system <span class="nt">-w</span>
</code></pre></div></div>

<p><img src="/static/img/multi-master-ha/pod-components.PNG" alt="pods" /></p>

<p><a name="installing-workers"><a></a></a></p>
<h3 id="23-installing-workers">2.3. Installing workers</h3>

<p>All of worker nodes can be joined to the cluster by command:</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span><span class="nb">sudo </span>kubeadm <span class="nb">join </span>10.0.2:6443 <span class="nt">--token</span> 7ju4yg.5x2xaj96xqx18qwq <span class="nt">--discovery-token-ca-cert-hash</span> sha256:4d7c5ef142e4faca3573984119df92a1a188115723f1e81dbb27eeb039cac1e0
</code></pre></div></div>

<p><strong>The result:</strong></p>

<p><img src="/static/img/multi-master-ha/nodess.PNG" alt="nodess" /></p>

<p><a name="-reference"><a></a></a></p>
<h2 id="3-reference">3. Reference</h2>

<p>[1] https://kubernetes.io/docs/setup/independent/high-availability/</p>

<p><em>Author: <a href="https://github.com/truongnh1992">truongnh1992</a></em> - Email: nguyenhaitruonghp[at]gmail[dot]com</p>

:ET